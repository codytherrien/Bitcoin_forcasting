{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin = yf.Ticker('BTC-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = bitcoin.history(period='max', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-09-17</th>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-18</th>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-19</th>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-20</th>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-21</th>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume  \\\n",
       "Date                                                                   \n",
       "2014-09-17  465.864014  468.174011  452.421997  457.334015  21056800   \n",
       "2014-09-18  456.859985  456.859985  413.104004  424.440002  34483200   \n",
       "2014-09-19  424.102997  427.834991  384.532013  394.795990  37919700   \n",
       "2014-09-20  394.673004  423.295990  389.882996  408.903992  36863600   \n",
       "2014-09-21  408.084991  412.425995  393.181000  398.821014  26580100   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2014-09-17          0             0  \n",
       "2014-09-18          0             0  \n",
       "2014-09-19          0             0  \n",
       "2014-09-20          0             0  \n",
       "2014-09-21          0             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "def preprocessing(data, curr_lay):\n",
    "    close_price = data['Close']\n",
    "    tsg = TimeseriesGenerator(close_price, close_price, length=curr_lay)\n",
    "    X, y = tsg[0]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training_len = int(len(inputs)*0.8)\n",
    "#X_train = X[:training_len]\n",
    "#y_train = y[:training_len]\n",
    "#\n",
    "#X_test = X[training_len:]\n",
    "#y_test = y[training_len:]\n",
    "X, y = preprocessing(history, 5)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras import layers\n",
    "\n",
    "def build_model(curr_lay):\n",
    "    m = Sequential()\n",
    "    m.add(layers.Dense(64, activation='relu', input_shape=(curr_lay,)))\n",
    "    m.add(layers.Dense(64, activation='relu'))\n",
    "    m.add(layers.Dense(1))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_models(data, min_layers, max_layers, epochs):\n",
    "    models = {}\n",
    "    for curr_lay in range(min_layers, max_layers+1):\n",
    "        X, y = preprocessing(data, curr_lay)\n",
    "        \n",
    "        training_len = int(len(data)*0.8)\n",
    "        X_train = X[:training_len]\n",
    "        y_train = y[:training_len]\n",
    "        \n",
    "        X_test = X[training_len:]\n",
    "        y_test = y[training_len:]\n",
    "        \n",
    "        m = build_model(curr_lay)\n",
    "        print('Training Model...')\n",
    "        m.compile(optimizer='adam', loss='mse') \n",
    "        h = m.fit(X_train, y_train,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=32,\n",
    "                  validation_data=(X_test, y_test))\n",
    "        \n",
    "        model_info = {'model': m, 'history': h.history}\n",
    "        models[curr_lay] = model_info\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 58169.0062\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 28588.7918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 10628.2822\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1855.4447\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 531.2554\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1917.5889\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2664.6042\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2141.3488\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 944.3385\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 416.8596\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 347.1289\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 481.0987\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 545.4640\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 474.7014\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 357.6315\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 241.8879\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 463.520 - 0s 14ms/step - loss: 349.1329\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 323.8351\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 328.9640\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 284.9623\n",
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 94889.6984\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 60357.9922\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 35605.1828\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 17460.0766\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6470.9196\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1067.9991\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 490.3258\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1804.0485\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2486.5089\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2035.7629\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 996.4803\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 410.3664\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 315.0810\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 406.1694\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 461.7216\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 405.0771\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 349.3186\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 291.1602\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 258.9418\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 247.9038\n",
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 45092.6320\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 15997.9541\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2411.6303\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 718.4424\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3035.7158\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3303.2778\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1441.6815\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 437.8951\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 414.7235\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 617.4388\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 685.5965\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 418.4904\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 321.5961\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 330.2813\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 331.2866\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 389.4329\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 271.0935\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 338.9439\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 273.4712\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 327.6848\n",
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 15219.7152\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1036.3957\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2917.7195\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2161.7269\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 545.4588\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 885.7152\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1018.6907\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 586.4557\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 598.8341\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 634.9102\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 562.0938\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 471.639 - 0s 12ms/step - loss: 486.9606\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 500.0528\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 587.0525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 461.6096\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 418.0384\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 270.505 - 0s 12ms/step - loss: 418.9408\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 449.8456\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 553.8660\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 505.6172\n",
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 148740.3062\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 94135.6578\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 48456.4086\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 20798.8984\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6744.9971\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1158.7039\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1276.7450\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2699.4481\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3155.6763\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2168.1081\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1110.0424\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 585.3471\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 723.1382\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 801.7370\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1005.8637\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 802.5880\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 544.5115\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 644.6831\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 699.4791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 707.8062\n",
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 28148.0500\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4736.3949\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1466.6236\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4010.4564\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2555.5610\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 715.4037\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 958.4750\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1352.1750\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 674.1426\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 587.2189\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 657.2482\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 606.1842\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 544.6338\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 527.7513\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 592.2402\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 582.3646\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 564.2656\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 547.4450\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 586.5765\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 504.5159\n",
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 33597.4512\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3897.7322\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3689.9400\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 6887.79 - 0s 11ms/step - loss: 5796.5671\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1488.3266\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 522.1265\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1297.5024\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1131.6944\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 412.6520\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 436.8332\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 584.0738\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 463.2505\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 365.0886\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 425.6682\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 427.9550\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 405.0017\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 377.3254\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 359.1757\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 315.0898\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 278.8334\n",
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 160801.3062\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 78872.0484\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 28158.3914\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3600.5484\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2747.6345\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7697.2309\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6683.8111\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2891.8252\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 858.6878\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1398.3738\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1795.1874\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1544.0225\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1021.7485\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1037.2335\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 970.4176\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1023.0598\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 874.8009\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 794.2664\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 929.3467\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 852.7806\n",
      "Training Model...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 74067.9516\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 16740.1607\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1616.9260\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5669.8120\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7189.3918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3090.8824\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 946.9769\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1412.1459\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1714.7316\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1180.9078\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 777.1706\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 827.4522\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 764.2448\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 584.6052\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 777.5727\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 721.2374\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 585.0622\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 558.6941\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 594.1505\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 540.0275\n"
     ]
    }
   ],
   "source": [
    "train_models = training_models(history, 2, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [53957.734375, 25898.8359375, 8827.6640625, 1364.752685546875, 654.649169921875, 2166.65087890625, 2755.879638671875, 1952.7305908203125, 851.0690307617188, 339.265869140625, 366.06207275390625, 513.6953125, 520.6204223632812, 407.9586181640625, 307.89239501953125, 287.8284912109375, 303.0662536621094, 311.3797607421875, 300.6893310546875, 288.19189453125]}\n",
      "{'loss': [87728.5546875, 56357.71875, 32840.8984375, 15712.9013671875, 5375.38134765625, 808.6008911132812, 684.8958740234375, 1950.291259765625, 2480.53125, 1857.0125732421875, 923.9012451171875, 390.13128662109375, 311.15863037109375, 402.7869873046875, 466.1495361328125, 428.97491455078125, 349.1795654296875, 304.4778137207031, 292.1784973144531, 301.36224365234375]}\n",
      "{'loss': [40424.8671875, 13127.62109375, 1795.0401611328125, 1023.2945556640625, 3143.174072265625, 2942.41943359375, 1230.40625, 388.4763488769531, 499.99609375, 745.1951293945312, 628.9935913085938, 385.17352294921875, 291.5939025878906, 352.1198425292969, 362.03729248046875, 326.340576171875, 300.0836486816406, 304.5910949707031, 307.99267578125, 301.38916015625]}\n",
      "{'loss': [11250.8837890625, 1153.3514404296875, 3047.973876953125, 1861.818359375, 541.9593505859375, 1041.346435546875, 1041.6688232421875, 593.044677734375, 616.3587646484375, 687.6885375976562, 532.1266479492188, 530.5587158203125, 544.8987426757812, 506.26116943359375, 500.2060546875, 489.9724426269531, 469.0224914550781, 474.0340576171875, 465.2406005859375, 452.38470458984375]}\n",
      "{'loss': [141539.15625, 83715.171875, 43289.65625, 18343.927734375, 5385.345703125, 992.1104125976562, 1371.98046875, 3063.87548828125, 3166.239501953125, 2045.67919921875, 969.8418579101562, 661.6741943359375, 811.5399169921875, 923.2137451171875, 847.21630859375, 699.0213623046875, 630.2236328125, 648.8988037109375, 661.738037109375, 652.6553344726562]}\n",
      "{'loss': [23792.37890625, 3359.25927734375, 1903.8729248046875, 4108.958984375, 2154.21875, 706.58251953125, 1087.35888671875, 1203.8741455078125, 720.3487548828125, 582.820556640625, 745.936279296875, 670.275634765625, 545.42578125, 605.52734375, 601.6163330078125, 557.4979248046875, 559.7106323242188, 560.52978515625, 541.3893432617188, 541.195556640625]}\n",
      "{'loss': [27503.505859375, 2543.274658203125, 4518.18359375, 4973.48681640625, 1203.292724609375, 620.7605590820312, 1414.785400390625, 1068.57861328125, 387.834716796875, 507.02313232421875, 632.4146728515625, 437.70941162109375, 381.80670166015625, 428.8055114746094, 387.44000244140625, 354.46728515625, 372.7440185546875, 362.98126220703125, 346.5462646484375, 351.31884765625]}\n",
      "{'loss': [147051.40625, 70138.046875, 23193.572265625, 2561.670654296875, 3743.93505859375, 8012.0693359375, 6127.76123046875, 2304.4951171875, 894.5531616210938, 1623.468505859375, 1902.9451904296875, 1436.1959228515625, 968.88134765625, 912.7332153320312, 1024.568115234375, 990.5813598632812, 888.8929443359375, 852.006591796875, 868.8212280273438, 863.1976318359375]}\n",
      "{'loss': [62796.10546875, 12715.6474609375, 1739.732421875, 6081.6494140625, 6453.4375, 2618.734619140625, 887.9827270507812, 1445.991455078125, 1730.368408203125, 1177.2938232421875, 724.8992919921875, 739.4650268554688, 729.8275756835938, 655.4424438476562, 654.5498657226562, 633.7474365234375, 592.9951171875, 581.03564453125, 570.1296997070312, 557.5360107421875]}\n"
     ]
    }
   ],
   "source": [
    "model_stats = {}\n",
    "for k, v in train_models.items():\n",
    "    print(v['history'])\n",
    "    #train_history = v['history']\n",
    "    #loss = train_history['loss'][-1]\n",
    "    #val_loss = train_history['val_loss'][-1]\n",
    "    #model_stats[k] = {'inputs': k, 'loss': loss, 'val_loss': val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25d13e1b8c8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = []\n",
    "indices = []\n",
    "for k, v in model_stats.items():\n",
    "    indices.append(k)\n",
    "    val_loss.append(v['val_loss'])\n",
    "plt.plot(indices, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
